# -*- coding: utf-8 -*-
"""Treinamento transfer Learning desafio.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F-fiku7F053OsH3CqzZaqNSnik5min-X
"""

!pip install tensorflow

# importando as bibliotecas
import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
import matplotlib.pyplot as plt
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import tensorflow_datasets as tfds

# Carregar o dataset e ver os splits disponíveis
dataset, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True)

# Exibir os splits
print(info.splits)

# Definindo a proporção de treino e teste
train_size = int(0.8 * 23262)  # 80% do total de exemplos

# Separando o conjunto de dados em treino e teste
train_data = dataset['train'].take(train_size)  # 80% para treino
test_data = dataset['train'].skip(train_size)  # 20% para teste

def preprocess_image(image, label):
    image = tf.image.resize(image, (150, 150))  # Redimensionando para 150x150
    image = image / 255.0  # Normalizando os valores dos pixels para [0, 1]
    return image, label

# Aplicando o pré-processamento nos dados de treino e teste
train_data = train_data.map(preprocess_image).batch(32).prefetch(tf.data.experimental.AUTOTUNE)
test_data = test_data.map(preprocess_image).batch(32).prefetch(tf.data.experimental.AUTOTUNE)

# Carregar modelo pré-treinado (MobileNetV2) sem as camadas finais
base_model = tf.keras.applications.MobileNetV2(input_shape=(150, 150, 3),
                                                include_top=False,  # Sem as camadas finais
                                                weights='imagenet')

# Congelar as camadas do modelo base para que não sejam treinadas
base_model.trainable = False

# Criar o modelo com Transfer Learning
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(1, activation='sigmoid')  # Para binário: gatos vs cachorros
])

# Compilar o modelo
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_data, epochs=12, validation_data=test_data)

test_loss, test_acc = model.evaluate(test_data)
print(f"Test accuracy: {test_acc}")

# Descongelar as últimas camadas do modelo base
base_model.trainable = True

# Congelar todas as camadas exceto as últimas 4
for layer in base_model.layers[:-4]:
    layer.trainable = False

# Recompilar o modelo com um learning rate menor
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Re-treinar o modelo
history_finetune = model.fit(train_data, epochs=10, validation_data=test_data)

